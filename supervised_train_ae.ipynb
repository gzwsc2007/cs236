{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e82dee64-b4b6-4415-9af8-c10d6ad95601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mansonw\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import wandb\n",
    "import time\n",
    "\n",
    "import utils\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_paths =  [\n",
    "    os.path.abspath(os.path.join('ronin/source'))  # RoNIN\n",
    "]\n",
    "for module_path in module_paths:\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "import data_glob_speed\n",
    "import data_ridi\n",
    "import cnn_ae_model\n",
    "\n",
    "# WANDB API Key: eefeec3d5632912a6bb9112f48d2dde3ca6e0658\n",
    "wandb.login()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab873c-af72-4da7-844e-f3b82abdf135",
   "metadata": {},
   "source": [
    "# Load RONIN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5089478-72a4-455f-8377-f00daf915815",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT_DIR = 'datasets'\n",
    "with open('datasets/self_sup_ronin_train_list.txt') as f:\n",
    "    ronin_data_list = [s.strip().split(',' or ' ')[0] for s in f.readlines() if len(s) > 0 and s[0] != '#']\n",
    "\n",
    "# Each item in the dataset is a (feature, target, seq_id, frame_id) tuple.\n",
    "# Each feature is a 6x200 array. Rows 0-2 are gyro, and rows 3-5 are accel (non gravity subtracted).\n",
    "# Both gyro and accels are in a gravity-aligned world frame (arbitrary yaw, but consistent throughout\n",
    "# the 200 frames)\n",
    "ronin_train_dataset = data_glob_speed.StridedSequenceDataset(data_glob_speed.GlobSpeedSequence,\n",
    "                                                             DATA_ROOT_DIR,\n",
    "                                                             ronin_data_list,\n",
    "                                                             cache_path='datasets/cache')\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(ronin_train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a946198d-1b59-4daa-97dd-8da2f0a3802f",
   "metadata": {},
   "source": [
    "# Load pre-trained CNN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437b2ac2-068b-4e9c-a692-74e15512d15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from checkpoints/CnnVae_feat=6_latent=128_firstChan=32_lastChan=128_fcDim=128/model-00496.pt\n",
      "Freezing encoder\n"
     ]
    }
   ],
   "source": [
    "# Parameters of the pre-trained CnnVae. Must match the saved model.\n",
    "latent_dim = 128\n",
    "first_chan_size = 32\n",
    "last_chan_size = 128\n",
    "ae_fc_dim = 128\n",
    "ae_model = cnn_ae_model.CnnAutoencoder(feature_dim=6,\n",
    "                             latent_dim=latent_dim,\n",
    "                             first_channel_size=first_chan_size,\n",
    "                             last_channel_size=last_chan_size,\n",
    "                             fc_dim=ae_fc_dim).to(device)\n",
    "\n",
    "# Load model from checkpoint.\n",
    "EPOCH_TO_LOAD = 496\n",
    "utils.load_model_by_name(ae_model, epoch=EPOCH_TO_LOAD)\n",
    "\n",
    "# Freeze encoder weights\n",
    "freeze_encoder = True\n",
    "if freeze_encoder:\n",
    "    print(\"Freezing encoder\")\n",
    "    for param in ae_model.enc.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae5566f-20e6-43b3-b116-82fdc13aa8bc",
   "metadata": {},
   "source": [
    "# Supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbab8ec0-2ea7-4fcd-aa56-ef826433f049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/anson/cs236/project/wandb/run-20231205_200521-0bazr8i3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ansonw/Pretrained-AE-With-Velocity-Decoder-RONIN-dataset-supervised/runs/0bazr8i3' target=\"_blank\">zesty-bee-1</a></strong> to <a href='https://wandb.ai/ansonw/Pretrained-AE-With-Velocity-Decoder-RONIN-dataset-supervised' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ansonw/Pretrained-AE-With-Velocity-Decoder-RONIN-dataset-supervised' target=\"_blank\">https://wandb.ai/ansonw/Pretrained-AE-With-Velocity-Decoder-RONIN-dataset-supervised</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ansonw/Pretrained-AE-With-Velocity-Decoder-RONIN-dataset-supervised/runs/0bazr8i3' target=\"_blank\">https://wandb.ai/ansonw/Pretrained-AE-With-Velocity-Decoder-RONIN-dataset-supervised/runs/0bazr8i3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Epoch 0, time usage: 29.847s, average loss: [0.2318633  0.29131722]/0.261590\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00000.pt\n",
      "-------------------------\n",
      "Epoch 1, time usage: 29.261s, average loss: [0.19004148 0.23182288]/0.210932\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00001.pt\n",
      "-------------------------\n",
      "Epoch 2, time usage: 29.545s, average loss: [0.18139102 0.22014995]/0.200770\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00002.pt\n",
      "-------------------------\n",
      "Epoch 3, time usage: 29.659s, average loss: [0.17796113 0.2144416 ]/0.196201\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00003.pt\n",
      "-------------------------\n",
      "Epoch 4, time usage: 29.500s, average loss: [0.17588176 0.21166103]/0.193771\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00004.pt\n",
      "-------------------------\n",
      "Epoch 5, time usage: 29.340s, average loss: [0.17454328 0.20934622]/0.191945\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00005.pt\n",
      "-------------------------\n",
      "Epoch 6, time usage: 29.695s, average loss: [0.17319812 0.20768757]/0.190443\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00006.pt\n",
      "-------------------------\n",
      "Epoch 7, time usage: 29.611s, average loss: [0.17291245 0.20623142]/0.189572\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00007.pt\n",
      "-------------------------\n",
      "Epoch 8, time usage: 29.512s, average loss: [0.1724614  0.20558304]/0.189022\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00008.pt\n",
      "-------------------------\n",
      "Epoch 9, time usage: 29.917s, average loss: [0.17175016 0.20474032]/0.188245\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00009.pt\n",
      "-------------------------\n",
      "Epoch 10, time usage: 29.901s, average loss: [0.17153788 0.20465608]/0.188097\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00010.pt\n",
      "-------------------------\n",
      "Epoch 11, time usage: 29.942s, average loss: [0.17127712 0.20435214]/0.187815\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00011.pt\n",
      "-------------------------\n",
      "Epoch 12, time usage: 29.635s, average loss: [0.17101862 0.20420335]/0.187611\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00012.pt\n",
      "-------------------------\n",
      "Epoch 13, time usage: 29.247s, average loss: [0.17058033 0.20363948]/0.187110\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00013.pt\n",
      "-------------------------\n",
      "Epoch 14, time usage: 30.058s, average loss: [0.17055859 0.20334202]/0.186950\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00014.pt\n",
      "-------------------------\n",
      "Epoch 15, time usage: 29.770s, average loss: [0.17038278 0.2030848 ]/0.186734\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00015.pt\n",
      "-------------------------\n",
      "Epoch 16, time usage: 29.145s, average loss: [0.17035069 0.20283385]/0.186592\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00016.pt\n",
      "-------------------------\n",
      "Epoch 17, time usage: 29.903s, average loss: [0.17047802 0.20248273]/0.186480\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00017.pt\n",
      "-------------------------\n",
      "Epoch 18, time usage: 29.738s, average loss: [0.16997725 0.20265023]/0.186314\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00018.pt\n",
      "-------------------------\n",
      "Epoch 19, time usage: 29.241s, average loss: [0.16995284 0.20220901]/0.186081\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00019.pt\n",
      "-------------------------\n",
      "Epoch 20, time usage: 29.562s, average loss: [0.16966245 0.20193991]/0.185801\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00020.pt\n",
      "-------------------------\n",
      "Epoch 21, time usage: 29.840s, average loss: [0.16946228 0.20211063]/0.185786\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00021.pt\n",
      "-------------------------\n",
      "Epoch 22, time usage: 29.765s, average loss: [0.16966298 0.20190841]/0.185786\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00022.pt\n",
      "-------------------------\n",
      "Epoch 23, time usage: 29.935s, average loss: [0.1694769  0.20168535]/0.185581\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00023.pt\n",
      "-------------------------\n",
      "Epoch 24, time usage: 29.905s, average loss: [0.16904022 0.2014451 ]/0.185243\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00024.pt\n",
      "-------------------------\n",
      "Epoch 25, time usage: 29.621s, average loss: [0.16877134 0.20122957]/0.185000\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00025.pt\n",
      "-------------------------\n",
      "Epoch 26, time usage: 29.528s, average loss: [0.16947153 0.20119324]/0.185332\n",
      "-------------------------\n",
      "Epoch 27, time usage: 29.587s, average loss: [0.16911125 0.20081456]/0.184963\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00027.pt\n",
      "-------------------------\n",
      "Epoch 28, time usage: 29.649s, average loss: [0.16885671 0.20099686]/0.184927\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00028.pt\n",
      "-------------------------\n",
      "Epoch 29, time usage: 29.577s, average loss: [0.16894916 0.2009678 ]/0.184958\n",
      "-------------------------\n",
      "Epoch 30, time usage: 29.677s, average loss: [0.16871186 0.20125157]/0.184982\n",
      "-------------------------\n",
      "Epoch 31, time usage: 29.709s, average loss: [0.16873051 0.20108427]/0.184907\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00031.pt\n",
      "-------------------------\n",
      "Epoch 32, time usage: 29.617s, average loss: [0.16884851 0.2007334 ]/0.184791\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00032.pt\n",
      "-------------------------\n",
      "Epoch 33, time usage: 29.572s, average loss: [0.16902654 0.20038892]/0.184708\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00033.pt\n",
      "-------------------------\n",
      "Epoch 34, time usage: 29.651s, average loss: [0.16812226 0.20062387]/0.184373\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00034.pt\n",
      "-------------------------\n",
      "Epoch 35, time usage: 29.647s, average loss: [0.16837983 0.2002501 ]/0.184315\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00035.pt\n",
      "-------------------------\n",
      "Epoch 36, time usage: 29.114s, average loss: [0.1685987  0.20084052]/0.184720\n",
      "-------------------------\n",
      "Epoch 37, time usage: 29.428s, average loss: [0.16849574 0.20046367]/0.184480\n",
      "-------------------------\n",
      "Epoch 38, time usage: 29.817s, average loss: [0.16855866 0.20048358]/0.184521\n",
      "-------------------------\n",
      "Epoch 39, time usage: 30.086s, average loss: [0.16833541 0.2002343 ]/0.184285\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00039.pt\n",
      "-------------------------\n",
      "Epoch 40, time usage: 30.122s, average loss: [0.16835037 0.20015183]/0.184251\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00040.pt\n",
      "-------------------------\n",
      "Epoch 41, time usage: 29.849s, average loss: [0.16854177 0.20045432]/0.184498\n",
      "-------------------------\n",
      "Epoch 42, time usage: 29.929s, average loss: [0.16869217 0.19975677]/0.184224\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00042.pt\n",
      "-------------------------\n",
      "Epoch 43, time usage: 29.541s, average loss: [0.16844462 0.20033817]/0.184391\n",
      "-------------------------\n",
      "Epoch 44, time usage: 29.968s, average loss: [0.16825739 0.19993898]/0.184098\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00044.pt\n",
      "-------------------------\n",
      "Epoch 45, time usage: 29.753s, average loss: [0.16807395 0.19987239]/0.183973\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00045.pt\n",
      "-------------------------\n",
      "Epoch 46, time usage: 29.824s, average loss: [0.16814935 0.19991876]/0.184034\n",
      "-------------------------\n",
      "Epoch 47, time usage: 29.671s, average loss: [0.16787313 0.19983278]/0.183853\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00047.pt\n",
      "-------------------------\n",
      "Epoch 48, time usage: 29.367s, average loss: [0.16812067 0.19985108]/0.183986\n",
      "-------------------------\n",
      "Epoch 49, time usage: 29.307s, average loss: [0.16788176 0.1999274 ]/0.183905\n",
      "-------------------------\n",
      "Epoch 50, time usage: 29.504s, average loss: [0.16740155 0.20008378]/0.183743\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00050.pt\n",
      "-------------------------\n",
      "Epoch 51, time usage: 29.666s, average loss: [0.16741434 0.1998805 ]/0.183647\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00051.pt\n",
      "-------------------------\n",
      "Epoch 52, time usage: 29.945s, average loss: [0.16731818 0.19987893]/0.183599\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00052.pt\n",
      "-------------------------\n",
      "Epoch 53, time usage: 30.183s, average loss: [0.16738826 0.19982271]/0.183605\n",
      "-------------------------\n",
      "Epoch 54, time usage: 29.704s, average loss: [0.1672359  0.19968762]/0.183462\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00054.pt\n",
      "-------------------------\n",
      "Epoch 55, time usage: 29.898s, average loss: [0.16746335 0.19961348]/0.183538\n",
      "-------------------------\n",
      "Epoch 56, time usage: 30.114s, average loss: [0.16751203 0.19967462]/0.183593\n",
      "-------------------------\n",
      "Epoch 57, time usage: 29.616s, average loss: [0.16722944 0.19977279]/0.183501\n",
      "-------------------------\n",
      "Epoch 58, time usage: 29.588s, average loss: [0.16702265 0.19942382]/0.183223\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00058.pt\n",
      "-------------------------\n",
      "Epoch 59, time usage: 29.848s, average loss: [0.16698389 0.19940165]/0.183193\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00059.pt\n",
      "-------------------------\n",
      "Epoch 60, time usage: 29.518s, average loss: [0.1671656 0.1995895]/0.183378\n",
      "-------------------------\n",
      "Epoch 61, time usage: 29.799s, average loss: [0.1671988  0.19981205]/0.183505\n",
      "-------------------------\n",
      "Epoch 62, time usage: 29.717s, average loss: [0.16688032 0.19965708]/0.183269\n",
      "-------------------------\n",
      "Epoch 63, time usage: 30.292s, average loss: [0.16711736 0.19901724]/0.183067\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00063.pt\n",
      "-------------------------\n",
      "Epoch 64, time usage: 31.572s, average loss: [0.1668728  0.19942349]/0.183148\n",
      "-------------------------\n",
      "Epoch 65, time usage: 30.339s, average loss: [0.16687982 0.19926547]/0.183073\n",
      "-------------------------\n",
      "Epoch 66, time usage: 30.880s, average loss: [0.16731593 0.19901772]/0.183167\n",
      "-------------------------\n",
      "Epoch 67, time usage: 30.369s, average loss: [0.16690993 0.19973709]/0.183324\n",
      "-------------------------\n",
      "Epoch 68, time usage: 30.091s, average loss: [0.16706873 0.19932704]/0.183198\n",
      "-------------------------\n",
      "Epoch 69, time usage: 29.674s, average loss: [0.16714278 0.1994632 ]/0.183303\n",
      "-------------------------\n",
      "Epoch 70, time usage: 30.104s, average loss: [0.1668185  0.19902416]/0.182921\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00070.pt\n",
      "-------------------------\n",
      "Epoch 71, time usage: 30.345s, average loss: [0.1669206  0.19907989]/0.183000\n",
      "-------------------------\n",
      "Epoch 72, time usage: 30.574s, average loss: [0.16668022 0.19895068]/0.182815\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00072.pt\n",
      "-------------------------\n",
      "Epoch 73, time usage: 30.492s, average loss: [0.16668494 0.198878  ]/0.182781\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00073.pt\n",
      "-------------------------\n",
      "Epoch 74, time usage: 31.008s, average loss: [0.16654247 0.1991535 ]/0.182848\n",
      "-------------------------\n",
      "Epoch 75, time usage: 31.089s, average loss: [0.16691926 0.19917853]/0.183049\n",
      "-------------------------\n",
      "Epoch 76, time usage: 30.524s, average loss: [0.16678423 0.19881985]/0.182802\n",
      "-------------------------\n",
      "Epoch 77, time usage: 30.211s, average loss: [0.16644022 0.19872251]/0.182581\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00077.pt\n",
      "-------------------------\n",
      "Epoch 78, time usage: 29.521s, average loss: [0.16675942 0.19865552]/0.182707\n",
      "-------------------------\n",
      "Epoch 79, time usage: 30.310s, average loss: [0.16665709 0.19876726]/0.182712\n",
      "-------------------------\n",
      "Epoch 80, time usage: 29.783s, average loss: [0.1669061  0.19878966]/0.182848\n",
      "-------------------------\n",
      "Epoch 81, time usage: 29.842s, average loss: [0.16643666 0.19897395]/0.182705\n",
      "-------------------------\n",
      "Epoch 82, time usage: 30.590s, average loss: [0.16627538 0.19860803]/0.182442\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00082.pt\n",
      "-------------------------\n",
      "Epoch 83, time usage: 30.871s, average loss: [0.16669574 0.19932713]/0.183011\n",
      "-------------------------\n",
      "Epoch 84, time usage: 30.544s, average loss: [0.16644262 0.19878107]/0.182612\n",
      "-------------------------\n",
      "Epoch 85, time usage: 30.985s, average loss: [0.16667727 0.19885609]/0.182767\n",
      "-------------------------\n",
      "Epoch 86, time usage: 30.258s, average loss: [0.16643888 0.19866797]/0.182553\n",
      "-------------------------\n",
      "Epoch 87, time usage: 30.733s, average loss: [0.16617507 0.19851421]/0.182345\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00087.pt\n",
      "-------------------------\n",
      "Epoch 88, time usage: 30.725s, average loss: [0.16672729 0.19870035]/0.182714\n",
      "-------------------------\n",
      "Epoch 89, time usage: 29.893s, average loss: [0.16675512 0.19868019]/0.182718\n",
      "-------------------------\n",
      "Epoch 90, time usage: 30.617s, average loss: [0.16698143 0.19862431]/0.182803\n",
      "-------------------------\n",
      "Epoch 91, time usage: 31.157s, average loss: [0.166574   0.19894525]/0.182760\n",
      "-------------------------\n",
      "Epoch 92, time usage: 30.546s, average loss: [0.16683516 0.19859144]/0.182713\n",
      "-------------------------\n",
      "Epoch 93, time usage: 30.188s, average loss: [0.16652606 0.19871604]/0.182621\n",
      "-------------------------\n",
      "Epoch 94, time usage: 29.768s, average loss: [0.16628332 0.19847724]/0.182380\n",
      "-------------------------\n",
      "Epoch 95, time usage: 29.368s, average loss: [0.16644724 0.19879791]/0.182623\n",
      "-------------------------\n",
      "Epoch 96, time usage: 29.878s, average loss: [0.16593884 0.19865648]/0.182298\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00096.pt\n",
      "-------------------------\n",
      "Epoch 97, time usage: 29.902s, average loss: [0.16651818 0.1984326 ]/0.182475\n",
      "-------------------------\n",
      "Epoch 98, time usage: 29.746s, average loss: [0.16658755 0.19867158]/0.182630\n",
      "-------------------------\n",
      "Epoch 99, time usage: 29.586s, average loss: [0.16653267 0.19835053]/0.182442\n",
      "-------------------------\n",
      "Epoch 100, time usage: 30.173s, average loss: [0.16660556 0.19872096]/0.182663\n",
      "-------------------------\n",
      "Epoch 101, time usage: 30.386s, average loss: [0.16682059 0.1980515 ]/0.182436\n",
      "-------------------------\n",
      "Epoch 102, time usage: 30.147s, average loss: [0.16637601 0.1983606 ]/0.182368\n",
      "-------------------------\n",
      "Epoch 103, time usage: 30.227s, average loss: [0.16646813 0.19856988]/0.182519\n",
      "-------------------------\n",
      "Epoch 104, time usage: 30.131s, average loss: [0.1665191  0.19803262]/0.182276\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00104.pt\n",
      "-------------------------\n",
      "Epoch 105, time usage: 30.257s, average loss: [0.16641162 0.19856149]/0.182487\n",
      "-------------------------\n",
      "Epoch 106, time usage: 30.005s, average loss: [0.1663835  0.19826199]/0.182323\n",
      "-------------------------\n",
      "Epoch 107, time usage: 29.997s, average loss: [0.16649784 0.19864184]/0.182570\n",
      "-------------------------\n",
      "Epoch 108, time usage: 30.082s, average loss: [0.16624269 0.19885941]/0.182551\n",
      "-------------------------\n",
      "Epoch 109, time usage: 29.906s, average loss: [0.16612533 0.19802941]/0.182077\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00109.pt\n",
      "-------------------------\n",
      "Epoch 110, time usage: 29.482s, average loss: [0.16606043 0.19839814]/0.182229\n",
      "-------------------------\n",
      "Epoch 111, time usage: 29.478s, average loss: [0.16638559 0.19826491]/0.182325\n",
      "-------------------------\n",
      "Epoch 112, time usage: 29.701s, average loss: [0.16651888 0.1982362 ]/0.182378\n",
      "-------------------------\n",
      "Epoch 113, time usage: 29.558s, average loss: [0.1664669  0.19806878]/0.182268\n",
      "-------------------------\n",
      "Epoch 114, time usage: 29.993s, average loss: [0.166529   0.19828601]/0.182407\n",
      "-------------------------\n",
      "Epoch 115, time usage: 29.619s, average loss: [0.16602686 0.19843273]/0.182230\n",
      "-------------------------\n",
      "Epoch 116, time usage: 29.916s, average loss: [0.16637315 0.1985294 ]/0.182451\n",
      "-------------------------\n",
      "Epoch 117, time usage: 30.420s, average loss: [0.16630758 0.19830322]/0.182305\n",
      "-------------------------\n",
      "Epoch 118, time usage: 30.678s, average loss: [0.16593668 0.19837943]/0.182158\n",
      "-------------------------\n",
      "Epoch 119, time usage: 30.500s, average loss: [0.16606323 0.19845305]/0.182258\n",
      "-------------------------\n",
      "Epoch 120, time usage: 30.733s, average loss: [0.16636893 0.19840498]/0.182387\n",
      "-------------------------\n",
      "Epoch 121, time usage: 30.492s, average loss: [0.16611707 0.19843434]/0.182276\n",
      "-------------------------\n",
      "Epoch 122, time usage: 30.664s, average loss: [0.16616258 0.19820046]/0.182182\n",
      "-------------------------\n",
      "Epoch 123, time usage: 30.877s, average loss: [0.1663706  0.19809802]/0.182234\n",
      "-------------------------\n",
      "Epoch 124, time usage: 30.790s, average loss: [0.16595294 0.19852714]/0.182240\n",
      "-------------------------\n",
      "Epoch 125, time usage: 29.966s, average loss: [0.16626279 0.19852014]/0.182391\n",
      "-------------------------\n",
      "Epoch 126, time usage: 29.656s, average loss: [0.16630168 0.19860151]/0.182452\n",
      "-------------------------\n",
      "Epoch 127, time usage: 30.000s, average loss: [0.1660138  0.19853456]/0.182274\n",
      "-------------------------\n",
      "Epoch 128, time usage: 30.876s, average loss: [0.16627793 0.19819587]/0.182237\n",
      "-------------------------\n",
      "Epoch 129, time usage: 30.289s, average loss: [0.16607016 0.19817594]/0.182123\n",
      "-------------------------\n",
      "Epoch 130, time usage: 30.844s, average loss: [0.16625427 0.19821922]/0.182237\n",
      "-------------------------\n",
      "Epoch 131, time usage: 30.843s, average loss: [0.16613373 0.19804813]/0.182091\n",
      "-------------------------\n",
      "Epoch 132, time usage: 30.573s, average loss: [0.16611567 0.19801572]/0.182066\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00132.pt\n",
      "-------------------------\n",
      "Epoch 133, time usage: 30.269s, average loss: [0.1658573  0.19804835]/0.181953\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00133.pt\n",
      "-------------------------\n",
      "Epoch 134, time usage: 30.741s, average loss: [0.16626012 0.19817653]/0.182218\n",
      "-------------------------\n",
      "Epoch 135, time usage: 30.383s, average loss: [0.16585763 0.19838804]/0.182123\n",
      "-------------------------\n",
      "Epoch 136, time usage: 30.419s, average loss: [0.1661738  0.19855559]/0.182365\n",
      "-------------------------\n",
      "Epoch 137, time usage: 29.816s, average loss: [0.16630287 0.19817646]/0.182240\n",
      "-------------------------\n",
      "Epoch 138, time usage: 30.232s, average loss: [0.16597652 0.1984167 ]/0.182197\n",
      "-------------------------\n",
      "Epoch 139, time usage: 30.115s, average loss: [0.16594143 0.19804937]/0.181995\n",
      "-------------------------\n",
      "Epoch 140, time usage: 30.445s, average loss: [0.16606015 0.19808976]/0.182075\n",
      "-------------------------\n",
      "Epoch 141, time usage: 30.839s, average loss: [0.16606401 0.19766548]/0.181865\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00141.pt\n",
      "-------------------------\n",
      "Epoch 142, time usage: 30.779s, average loss: [0.16577277 0.19817325]/0.181973\n",
      "-------------------------\n",
      "Epoch 143, time usage: 30.057s, average loss: [0.16567929 0.19805358]/0.181866\n",
      "-------------------------\n",
      "Epoch 144, time usage: 30.766s, average loss: [0.16613916 0.1979324 ]/0.182036\n",
      "-------------------------\n",
      "Epoch 145, time usage: 30.924s, average loss: [0.16581345 0.19823799]/0.182026\n",
      "-------------------------\n",
      "Epoch 146, time usage: 29.774s, average loss: [0.16608588 0.19816767]/0.182127\n",
      "-------------------------\n",
      "Epoch 147, time usage: 30.378s, average loss: [0.16606173 0.19817883]/0.182120\n",
      "-------------------------\n",
      "Epoch 148, time usage: 30.884s, average loss: [0.16622896 0.19804744]/0.182138\n",
      "-------------------------\n",
      "Epoch 149, time usage: 30.778s, average loss: [0.1660522  0.19793335]/0.181993\n",
      "-------------------------\n",
      "Epoch 150, time usage: 30.397s, average loss: [0.1660757  0.19832668]/0.182201\n",
      "-------------------------\n",
      "Epoch 151, time usage: 30.152s, average loss: [0.16594803 0.19798015]/0.181964\n",
      "-------------------------\n",
      "Epoch 152, time usage: 29.808s, average loss: [0.16616248 0.19815283]/0.182158\n",
      "-------------------------\n",
      "Epoch 153, time usage: 30.455s, average loss: [0.16590798 0.19802849]/0.181968\n",
      "-------------------------\n",
      "Epoch 154, time usage: 30.732s, average loss: [0.1659391  0.19799232]/0.181966\n",
      "-------------------------\n",
      "Epoch 155, time usage: 29.691s, average loss: [0.16603345 0.19785994]/0.181947\n",
      "-------------------------\n",
      "Epoch 156, time usage: 29.657s, average loss: [0.16589178 0.19760148]/0.181747\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00156.pt\n",
      "-------------------------\n",
      "Epoch 157, time usage: 29.650s, average loss: [0.1660843  0.19769485]/0.181890\n",
      "-------------------------\n",
      "Epoch 158, time usage: 29.680s, average loss: [0.1659493  0.19801883]/0.181984\n",
      "-------------------------\n",
      "Epoch 159, time usage: 30.017s, average loss: [0.16591702 0.19785081]/0.181884\n",
      "-------------------------\n",
      "Epoch 160, time usage: 29.856s, average loss: [0.1662249  0.19801371]/0.182119\n",
      "-------------------------\n",
      "Epoch 161, time usage: 29.664s, average loss: [0.16590503 0.19798712]/0.181946\n",
      "-------------------------\n",
      "Epoch 162, time usage: 30.111s, average loss: [0.16598271 0.1974917 ]/0.181737\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00162.pt\n",
      "-------------------------\n",
      "Epoch 163, time usage: 29.824s, average loss: [0.16625485 0.19763418]/0.181945\n",
      "-------------------------\n",
      "Epoch 164, time usage: 29.198s, average loss: [0.16591953 0.19822563]/0.182073\n",
      "-------------------------\n",
      "Epoch 165, time usage: 29.457s, average loss: [0.16576558 0.19800062]/0.181883\n",
      "-------------------------\n",
      "Epoch 166, time usage: 29.377s, average loss: [0.16565861 0.19770452]/0.181682\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00166.pt\n",
      "-------------------------\n",
      "Epoch 167, time usage: 30.137s, average loss: [0.16579285 0.19767068]/0.181732\n",
      "-------------------------\n",
      "Epoch 168, time usage: 29.763s, average loss: [0.16611327 0.1979524 ]/0.182033\n",
      "-------------------------\n",
      "Epoch 169, time usage: 29.712s, average loss: [0.16596404 0.19793941]/0.181952\n",
      "-------------------------\n",
      "Epoch 170, time usage: 29.618s, average loss: [0.16585508 0.19764735]/0.181751\n",
      "-------------------------\n",
      "Epoch 171, time usage: 29.362s, average loss: [0.16608465 0.19800071]/0.182043\n",
      "-------------------------\n",
      "Epoch 172, time usage: 29.608s, average loss: [0.16606557 0.19806354]/0.182065\n",
      "-------------------------\n",
      "Epoch 173, time usage: 29.909s, average loss: [0.16571859 0.19744098]/0.181580\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00173.pt\n",
      "-------------------------\n",
      "Epoch 174, time usage: 29.594s, average loss: [0.16594343 0.19782339]/0.181883\n",
      "-------------------------\n",
      "Epoch 175, time usage: 29.373s, average loss: [0.16567478 0.19812976]/0.181902\n",
      "-------------------------\n",
      "Epoch 176, time usage: 30.071s, average loss: [0.16581143 0.19729054]/0.181551\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00176.pt\n",
      "-------------------------\n",
      "Epoch 177, time usage: 29.590s, average loss: [0.16589016 0.19818027]/0.182035\n",
      "-------------------------\n",
      "Epoch 178, time usage: 29.722s, average loss: [0.16601966 0.19759826]/0.181809\n",
      "-------------------------\n",
      "Epoch 179, time usage: 29.629s, average loss: [0.16593915 0.19795513]/0.181947\n",
      "-------------------------\n",
      "Epoch 180, time usage: 29.721s, average loss: [0.16580442 0.19753598]/0.181670\n",
      "-------------------------\n",
      "Epoch 181, time usage: 29.883s, average loss: [0.1659845  0.19755784]/0.181771\n",
      "-------------------------\n",
      "Epoch 182, time usage: 30.055s, average loss: [0.16620211 0.19764352]/0.181923\n",
      "-------------------------\n",
      "Epoch 183, time usage: 29.908s, average loss: [0.16582665 0.19765653]/0.181742\n",
      "-------------------------\n",
      "Epoch 184, time usage: 29.825s, average loss: [0.16578293 0.1977619 ]/0.181772\n",
      "-------------------------\n",
      "Epoch 185, time usage: 29.873s, average loss: [0.1657595  0.19818848]/0.181974\n",
      "-------------------------\n",
      "Epoch 186, time usage: 29.592s, average loss: [0.16571894 0.19724008]/0.181480\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00186.pt\n",
      "-------------------------\n",
      "Epoch 187, time usage: 29.511s, average loss: [0.16591851 0.19789685]/0.181908\n",
      "-------------------------\n",
      "Epoch 188, time usage: 29.345s, average loss: [0.16594842 0.19827782]/0.182113\n",
      "-------------------------\n",
      "Epoch 189, time usage: 29.329s, average loss: [0.1657155  0.19773255]/0.181724\n",
      "-------------------------\n",
      "Epoch 190, time usage: 29.733s, average loss: [0.16575505 0.19814481]/0.181950\n",
      "-------------------------\n",
      "Epoch 191, time usage: 29.572s, average loss: [0.16587843 0.1974957 ]/0.181687\n",
      "-------------------------\n",
      "Epoch 192, time usage: 29.695s, average loss: [0.16571106 0.19732755]/0.181519\n",
      "-------------------------\n",
      "Epoch 193, time usage: 29.566s, average loss: [0.16567078 0.19731332]/0.181492\n",
      "-------------------------\n",
      "Epoch 194, time usage: 29.648s, average loss: [0.16569936 0.19794218]/0.181821\n",
      "-------------------------\n",
      "Epoch 195, time usage: 29.724s, average loss: [0.1659022  0.19754913]/0.181726\n",
      "-------------------------\n",
      "Epoch 196, time usage: 29.796s, average loss: [0.16553257 0.19775413]/0.181643\n",
      "-------------------------\n",
      "Epoch 197, time usage: 29.588s, average loss: [0.16587085 0.19778997]/0.181830\n",
      "-------------------------\n",
      "Epoch 198, time usage: 29.520s, average loss: [0.16567084 0.19768615]/0.181679\n",
      "-------------------------\n",
      "Epoch 199, time usage: 29.361s, average loss: [0.16570063 0.19731553]/0.181508\n",
      "-------------------------\n",
      "Epoch 200, time usage: 29.289s, average loss: [0.16578476 0.19731538]/0.181550\n",
      "-------------------------\n",
      "Epoch 201, time usage: 29.320s, average loss: [0.16578354 0.19773003]/0.181757\n",
      "-------------------------\n",
      "Epoch 202, time usage: 29.854s, average loss: [0.16584805 0.19749424]/0.181671\n",
      "-------------------------\n",
      "Epoch 203, time usage: 29.840s, average loss: [0.16575935 0.19742385]/0.181592\n",
      "-------------------------\n",
      "Epoch 204, time usage: 29.445s, average loss: [0.1657611  0.19804741]/0.181904\n",
      "-------------------------\n",
      "Epoch 205, time usage: 29.572s, average loss: [0.16560714 0.19778277]/0.181695\n",
      "-------------------------\n",
      "Epoch 206, time usage: 29.715s, average loss: [0.16554166 0.1973937 ]/0.181468\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00206.pt\n",
      "-------------------------\n",
      "Epoch 207, time usage: 29.991s, average loss: [0.16558085 0.19749206]/0.181536\n",
      "-------------------------\n",
      "Epoch 208, time usage: 29.537s, average loss: [0.16539106 0.1976438 ]/0.181517\n",
      "-------------------------\n",
      "Epoch 209, time usage: 29.667s, average loss: [0.16577098 0.19702108]/0.181396\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00209.pt\n",
      "-------------------------\n",
      "Epoch 210, time usage: 29.427s, average loss: [0.1657622 0.1972901]/0.181526\n",
      "-------------------------\n",
      "Epoch 211, time usage: 29.415s, average loss: [0.16585357 0.19743232]/0.181643\n",
      "-------------------------\n",
      "Epoch 212, time usage: 29.464s, average loss: [0.16586562 0.19735143]/0.181609\n",
      "-------------------------\n",
      "Epoch 213, time usage: 29.481s, average loss: [0.1656244  0.19728994]/0.181457\n",
      "-------------------------\n",
      "Epoch 214, time usage: 29.400s, average loss: [0.16574953 0.19755669]/0.181653\n",
      "-------------------------\n",
      "Epoch 215, time usage: 29.640s, average loss: [0.16546096 0.19765782]/0.181559\n",
      "-------------------------\n",
      "Epoch 216, time usage: 29.429s, average loss: [0.1655914  0.19757521]/0.181583\n",
      "-------------------------\n",
      "Epoch 217, time usage: 29.382s, average loss: [0.16544847 0.19730583]/0.181377\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00217.pt\n",
      "-------------------------\n",
      "Epoch 218, time usage: 29.406s, average loss: [0.16561796 0.19803229]/0.181825\n",
      "-------------------------\n",
      "Epoch 219, time usage: 29.534s, average loss: [0.16544516 0.19748287]/0.181464\n",
      "-------------------------\n",
      "Epoch 220, time usage: 29.482s, average loss: [0.16544744 0.19759648]/0.181522\n",
      "-------------------------\n",
      "Epoch 221, time usage: 29.599s, average loss: [0.16545434 0.1972812 ]/0.181368\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00221.pt\n",
      "-------------------------\n",
      "Epoch 222, time usage: 29.496s, average loss: [0.16547248 0.1973194 ]/0.181396\n",
      "-------------------------\n",
      "Epoch 223, time usage: 29.505s, average loss: [0.16535081 0.19785984]/0.181605\n",
      "-------------------------\n",
      "Epoch 224, time usage: 29.410s, average loss: [0.16547492 0.19749413]/0.181485\n",
      "-------------------------\n",
      "Epoch 225, time usage: 29.093s, average loss: [0.16520004 0.1980692 ]/0.181635\n",
      "-------------------------\n",
      "Epoch 226, time usage: 29.480s, average loss: [0.16573842 0.19759744]/0.181668\n",
      "-------------------------\n",
      "Epoch 227, time usage: 29.780s, average loss: [0.16564143 0.19781044]/0.181726\n",
      "-------------------------\n",
      "Epoch 228, time usage: 29.514s, average loss: [0.16532819 0.1977317 ]/0.181530\n",
      "-------------------------\n",
      "Epoch 229, time usage: 29.428s, average loss: [0.16563967 0.19719958]/0.181420\n",
      "-------------------------\n",
      "Epoch 230, time usage: 29.618s, average loss: [0.16547005 0.1976266 ]/0.181548\n",
      "-------------------------\n",
      "Epoch 231, time usage: 29.513s, average loss: [0.16593702 0.19768181]/0.181809\n",
      "-------------------------\n",
      "Epoch 232, time usage: 30.073s, average loss: [0.16543186 0.19751239]/0.181472\n",
      "-------------------------\n",
      "Epoch 233, time usage: 29.928s, average loss: [0.1655601 0.1971155]/0.181338\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00233.pt\n",
      "-------------------------\n",
      "Epoch 234, time usage: 29.264s, average loss: [0.16551627 0.19710872]/0.181313\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00234.pt\n",
      "-------------------------\n",
      "Epoch 235, time usage: 29.588s, average loss: [0.16535842 0.19752236]/0.181440\n",
      "-------------------------\n",
      "Epoch 236, time usage: 29.476s, average loss: [0.1653335  0.19753346]/0.181433\n",
      "-------------------------\n",
      "Epoch 237, time usage: 29.637s, average loss: [0.1656095  0.19775718]/0.181683\n",
      "-------------------------\n",
      "Epoch 238, time usage: 30.138s, average loss: [0.165538  0.1977471]/0.181643\n",
      "-------------------------\n",
      "Epoch 239, time usage: 29.396s, average loss: [0.16562963 0.19744366]/0.181537\n",
      "-------------------------\n",
      "Epoch 240, time usage: 29.485s, average loss: [0.16594844 0.19713058]/0.181540\n",
      "-------------------------\n",
      "Epoch 241, time usage: 30.163s, average loss: [0.1656065  0.19756253]/0.181585\n",
      "-------------------------\n",
      "Epoch 242, time usage: 29.610s, average loss: [0.16529797 0.19740084]/0.181349\n",
      "-------------------------\n",
      "Epoch 243, time usage: 29.336s, average loss: [0.16542993 0.19746383]/0.181447\n",
      "-------------------------\n",
      "Epoch 244, time usage: 29.384s, average loss: [0.16536072 0.19773154]/0.181546\n",
      "-------------------------\n",
      "Epoch 245, time usage: 29.879s, average loss: [0.16547517 0.1975069 ]/0.181491\n",
      "-------------------------\n",
      "Epoch 246, time usage: 29.836s, average loss: [0.16549644 0.19755702]/0.181527\n",
      "-------------------------\n",
      "Epoch 247, time usage: 29.644s, average loss: [0.165421   0.19722463]/0.181323\n",
      "-------------------------\n",
      "Epoch 248, time usage: 29.869s, average loss: [0.16537547 0.19769639]/0.181536\n",
      "-------------------------\n",
      "Epoch 249, time usage: 29.400s, average loss: [0.1656881  0.19750859]/0.181598\n",
      "-------------------------\n",
      "Epoch 250, time usage: 29.081s, average loss: [0.16531403 0.19777754]/0.181546\n",
      "-------------------------\n",
      "Epoch 251, time usage: 29.068s, average loss: [0.1656745  0.19738932]/0.181532\n",
      "-------------------------\n",
      "Epoch 252, time usage: 29.392s, average loss: [0.16538656 0.1969062 ]/0.181146\n",
      "Model saved to  checkpoints/Sup_with_AE_lr_0.0001_FC_128/model-00252.pt\n",
      "-------------------------\n",
      "Epoch 253, time usage: 29.563s, average loss: [0.16529754 0.1973175 ]/0.181308\n",
      "-------------------------\n",
      "Epoch 254, time usage: 29.898s, average loss: [0.16560306 0.19754672]/0.181575\n",
      "-------------------------\n",
      "Epoch 255, time usage: 29.497s, average loss: [0.1654656 0.1974261]/0.181446\n",
      "-------------------------\n",
      "Epoch 256, time usage: 29.720s, average loss: [0.16553263 0.19743082]/0.181482\n",
      "-------------------------\n",
      "Epoch 257, time usage: 29.646s, average loss: [0.16536944 0.19698814]/0.181179\n",
      "-------------------------\n",
      "Epoch 258, time usage: 29.648s, average loss: [0.1656113 0.1976398]/0.181626\n",
      "-------------------------\n",
      "Epoch 259, time usage: 29.678s, average loss: [0.16554461 0.19754685]/0.181546\n",
      "-------------------------\n",
      "Epoch 260, time usage: 29.633s, average loss: [0.1653353  0.19777566]/0.181555\n",
      "-------------------------\n",
      "Epoch 261, time usage: 29.514s, average loss: [0.1652201  0.19710143]/0.181161\n",
      "-------------------------\n",
      "Epoch 262, time usage: 29.672s, average loss: [0.16549832 0.19757645]/0.181537\n",
      "-------------------------\n",
      "Epoch 263, time usage: 30.055s, average loss: [0.16545792 0.19740151]/0.181430\n",
      "-------------------------\n",
      "Epoch 264, time usage: 29.586s, average loss: [0.16559498 0.19756085]/0.181578\n",
      "-------------------------\n",
      "Epoch 265, time usage: 29.406s, average loss: [0.16557436 0.19719014]/0.181382\n",
      "-------------------------\n",
      "Epoch 266, time usage: 29.465s, average loss: [0.16534771 0.19727452]/0.181311\n",
      "-------------------------\n",
      "Epoch 267, time usage: 29.456s, average loss: [0.16553666 0.19701816]/0.181277\n",
      "-------------------------\n",
      "Epoch 268, time usage: 29.515s, average loss: [0.16572295 0.19717777]/0.181450\n",
      "-------------------------\n",
      "Epoch 269, time usage: 29.397s, average loss: [0.16562071 0.19716474]/0.181393\n",
      "-------------------------\n",
      "Epoch 270, time usage: 29.387s, average loss: [0.16557798 0.19706462]/0.181321\n",
      "-------------------------\n",
      "Epoch 271, time usage: 29.621s, average loss: [0.16547841 0.1971397 ]/0.181309\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(loss)\n\u001b[1;32m     52\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 53\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m train_outs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(train_outs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     55\u001b[0m train_targets \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(train_targets, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/cs236/venvs/project/lib/python3.10/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/cs236/venvs/project/lib/python3.10/site-packages/torch/optim/optimizer.py:58\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_use_grad_for_differentiable\u001b[39m(func):\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_use_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m     60\u001b[0m         prev_grad \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vel_fc_dims = [128]\n",
    "dropout = 0.25\n",
    "lr = 1e-4\n",
    "vel_model = cnn_ae_model.VelocityRegressor(ae_model.enc, vel_fc_dims, num_outputs=2, dropout=dropout).to(device)\n",
    "\n",
    "def get_model_name():\n",
    "    name = \"Sup_with_AE_lr_{}_FC\".format(lr)\n",
    "    for fc_dim in vel_fc_dims:\n",
    "        name += \"_{}\".format(fc_dim)\n",
    "    name += \"\" if freeze_encoder else \"_unfreeze_enc\"\n",
    "    return name\n",
    "\n",
    "# WANDB setup\n",
    "project_name = \"Pretrained-AE-With-Velocity-Decoder-RONIN-dataset-supervised\" + (\"\" if freeze_encoder else \"-unfreeze-encoder\")\n",
    "wandb_run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=project_name,\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"vel_fc_dims\": vel_fc_dims,\n",
    "        \"dropout\": dropout,\n",
    "        \"lr\": lr,\n",
    "        \"latent_dim\": latent_dim,\n",
    "        \"encoder_first_chan_size\": first_chan_size,\n",
    "        \"encoder_last_chan_size\": last_chan_size,\n",
    "        \"encoder_fc_dim\": ae_fc_dim,\n",
    "        \"batch_size\": batch_size\n",
    "})\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(vel_model.parameters(), lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10, verbose=True, eps=1e-12)\n",
    "\n",
    "if 'start_epoch' not in locals():\n",
    "    start_epoch = 0\n",
    "\n",
    "max_epochs = 5000\n",
    "best_loss = np.inf\n",
    "train_losses_all = []\n",
    "for epoch in range(start_epoch, max_epochs):\n",
    "    start_t = time.time()\n",
    "    vel_model.train()\n",
    "    train_outs, train_targets = [], []\n",
    "    for batch_id, (feat, targ, _, _) in enumerate(train_loader):\n",
    "        feat, targ = feat.to(device), targ.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = vel_model(feat)\n",
    "        train_outs.append(pred.cpu().detach().numpy())\n",
    "        train_targets.append(targ.cpu().detach().numpy())\n",
    "        loss = criterion(pred, targ)\n",
    "        loss = torch.mean(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_outs = np.concatenate(train_outs, axis=0)\n",
    "    train_targets = np.concatenate(train_targets, axis=0)\n",
    "    train_losses = np.average((train_outs - train_targets) ** 2, axis=0)\n",
    "\n",
    "    end_t = time.time()\n",
    "    print('-------------------------')\n",
    "    print('Epoch {}, time usage: {:.3f}s, average loss: {}/{:.6f}'.format(\n",
    "        epoch, end_t - start_t, train_losses, np.average(train_losses)))\n",
    "    avg_loss = np.average(train_losses)\n",
    "    train_losses_all.append(avg_loss)\n",
    "\n",
    "    wandb_run.log({\"vel_x_loss\": train_losses[0],\n",
    "                   \"vel_y_loss\": train_losses[1],\n",
    "                   \"avg_loss\": avg_loss})\n",
    "\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        utils.save_states(get_model_name(), epoch, vel_model, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
